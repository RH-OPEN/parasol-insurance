= Pipeline for processing claims
include::_attributes.adoc[]

== パイプラインは何をするのでしょうか?
Web アプリをデプロイしたので、一部の Claim がまだ処理されていないことがわかります。

[.bordershadow]
image::05/05-new-app-claim-unprocessed.jpg[]

もちろん、この処理を実行したいのですし、完全に自動化できればさらに良いです。

そのために、アドホックに実行することも、信頼性チェック パイプラインと同様にスケジュールすることもできるパイプラインを使用します。ただし、この場合、技術的にはデータ サイエンス パイプラインではありません。それは素の Tekton パイプラインに近いものになります。

// このパイプラインは、自動的にトリガーできる ArgoCD または Tekton パイプラインを作成するための良い開始点でもあります。

== パイプラインの中には何が入っているのでしょうか？

VSCode ワークベンチ内 (閉じたり停止してしまっている場合は、再起動してください) で `parasol-insurance/lab-materials/05/05-05` に移動すると、さまざまなファイルが表示されます。
[.bordershadow]
image::05/05-process-claims-yaml.png[]


今回は、**パイプライン** `process-claims-pipeline.yaml` の **yaml definition** を使用して Claim を処理します。

パイプラインの主なファイルとその機能は次のとおりです。

* *get_claims* - データベースに接続し、未処理の Claim を取得し、ファイル `claims.json` を通じて他のタスクに渡されるリストに追加します。
* 次のスクリプトは、処理する必要があるすべてのクレームを調べ、テキストの本文全体を使用して重要な特徴を見つけ、その結果をデータベースにプッシュします。
** *get_location* - 事故現場を特定します
** *get_accident_time* - 事故が起きたの時刻を見つける
** *summarize_text* - テキストの短い要約を作成します
** *get_sentiment* - 文章の感情を汲み取る
* *detect_objects* - Claim の画像をダウンロードし、Serveされている物体検出モデルを使用して画像内の損害を分類します。

== パイプラインアーティファクトのストレージ

パイプラインを実行する前に、中間ファイルと結果を保存する場所が必要です。 このラボでは、このストレージはすでに作成されています。

クラスター ストレージの `Data Pipeline` が、{rhoai} ダッシュボードのプロジェクト **Cluster Storage** セクションで利用可能であることを確認できます。

[.bordershadow]
image::05/05-data-pipeline-storage.png[]

== パイプラインをインポートする

パイプラインをインポートするには、まず `process-claims-pipeline.yaml` file locally.ファイルをローカルにダウンロードします。 `parasol-insurance/lab-materials/05/05-05` に移動して見つけます。


* まず `process-claims-pipeline.yaml` ファイルをラップトップのローカルにダウンロードします。
** VSCode ワークベンチで、ファイルを右クリックし、 **Download** を選択します。
** ファイルをラップトップ上のどこかに保存します。
* 次に、 {rhoai} ダッシュボードに移動します。
* これまで使用していたデータ サイエンス プロジェクトを選択します。
* **Pipelines** タブを選択します。
* **Import Pipeline** をクリックします。
+
[.bordershadow]
image::05/05-import-pipeline.png[import pipeline]

* 次に、ドラッグ アンド ドロップまたは Upload ボタンを使用して、 `process-claims-pipeline.yaml` ファイルをアップロードします。
* パイプラインに `Process Claims Pipeline` のような適切な名前を付けるようにしてください。
* 次のようになります。
+
[.bordershadow]
image::05/05-import-pipeline-highlighted.png[imported pipeline]

* **Import Pipeline** をクリックすると、Data Science Pipelines section にそれが表示されるはずです。
+
[.bordershadow]
image::05/05-process-claims-pipeline-imported.png[]

== パイプラインを実行する

* 右上のドロップダウン メニュー `Actions` から、 `Create Run` を選択します。（Kubeflow v1 SDK に関するポップアップは気にしないでください。以前のバージョンを使用している場合の単なる警告です。）
+
[.bordershadow]
image::05/05-create-run.png[create run]

* 次の設定を使用します。（他の設定はデフォルト値のままにします。)
** Run details->Name:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
Process Claim Run
** Parameters->claim_id:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
0
** Parameters->detection_endpoint:
[.lines_space]
[.console-input]
[source, text]
[subs=attributes+]
http://modelmesh-serving.{user}:8008

これは、ワークショップで以前に使用した物体検出エンドポイントへの同じルートです。

* 完了すると、次のようになります。
+
[.bordershadow]
image::05/05-run-settings-create-pipeline.png[run settings]

* claim_id を変更すると、処理するクレームを変更できることに注意してください。未処理の Claim をすべて処理するには、0 に設定します。

* **Create** をクリックして、実行を確認します。（開始までに 5 ～ 15 秒かかります。）
+
[.bordershadow]
image::05/05-process-claims.png[process]

== 結果を確認する

* パイプラインの実行が完了したら、アプリに移動して Claim を確認できます。
* すべての Claim が処理されたことがわかります。（ページを更新する必要がある場合があります。）
+
[.bordershadow]
image::05/05-process-claim3-app.jpg[claim3processed]

* Claim CLM502803 をクリックすると、処理されたことがわかります。
* 単なる長い本文の代わりに、概要、場所フィールド、事故時刻フィールド、感情フィールドが表示されます。
* また、損傷箇所に境界ボックスが表示された新しい画像があることもわかります。
+
[.bordershadow]
image::05/05-processed-claim.jpg[claim3processed]
